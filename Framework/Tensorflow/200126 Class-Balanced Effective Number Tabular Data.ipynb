{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd , sys\n",
    "import matplotlib.pyplot as plt\n",
    "import scikitplot as skplt\n",
    "from IPython.display import clear_output\n",
    "from sklearn.metrics import auc , roc_auc_score , confusion_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler , LabelEncoder\n",
    "import re , os\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import *\n",
    "from tensorflow.contrib.tensorboard.plugins import projector\n",
    "import scikitplot as skplt\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"/home/advice/Python/SR/Custom/\")\n",
    "from RAdam import RAdamOptimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "static = os.path.abspath(\"./Result\")\n",
    "ModelName = \"effective_number\"\n",
    "ResultPath = os.path.join(static , ModelName)    \n",
    "if tf.io.gfile.exists(ResultPath) :\n",
    "    tf.io.gfile.rmtree(ResultPath)\n",
    "    tf.io.gfile.makedirs(ResultPath)\n",
    "else :\n",
    "    tf.io.gfile.makedirs(ResultPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning:\n",
      "\n",
      "sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from optuna.integration import SkoptSampler\n",
    "import logging\n",
    "import plotly\n",
    "from optuna.logging import get_logger\n",
    "from optuna.structs import TrialState\n",
    "from optuna import type_checking\n",
    "from optuna.visualization.utils import _check_plotly_availability\n",
    "from optuna.visualization.utils import is_available\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emb(split =None, _len_=None , n = None , ratio = None , key=None) :\n",
    "    print(f\"Category : {key}\")\n",
    "    split = tf.reshape(split , shape=(-1,))\n",
    "    split = tf.to_int32(split)\n",
    "    if _len_ < n :\n",
    "        first =  _len_\n",
    "        to = _len_\n",
    "        Cat = tf.one_hot(split ,depth=_len_)\n",
    "        print(f\"[{key}] Onehot Shape : [{first}]\")\n",
    "    else :\n",
    "        first =  _len_\n",
    "        to = int(_len_/2)\n",
    "        # 2/_len_\n",
    "        embeddings = tf.Variable(tf.truncated_normal([first , to], \n",
    "                                                     stddev =  0.1 ) ,\n",
    "                                 dtype = tf.float32,name=key)  \n",
    "        mod = sys.modules[__name__]\n",
    "        setattr(mod, f'embedding_{key}',embeddings)\n",
    "        Cat = tf.nn.embedding_lookup(embeddings, split)\n",
    "        Cat = tf.nn.dropout(Cat , ratio)\n",
    "        print(f\"[{key}] Onehot Shape : [{first}] --> Embedding Shape : [{to}] \")\n",
    "    return Cat\n",
    "\n",
    "\n",
    "def tf_feature(X , objcol , objdict , InputdropoutRate, totalcol) :\n",
    "    with tf.name_scope(f\"FeatureX\") :\n",
    "        if objcol == [] :\n",
    "            featureX = tf.nn.dropout(X , InputdropoutRate)\n",
    "        else :\n",
    "            featureX = EmbeddingLayer(X , objdict , InputdropoutRate, totalcol)\n",
    "    return featureX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_mish(x) :\n",
    "    return x * tf.nn.tanh(tf.nn.softplus(x))\n",
    "\n",
    "def get_weight_variable(shape, name=None,\n",
    "                        type='xavier_uniform', regularize=True, **kwargs):\n",
    "    initialise_from_constant = False\n",
    "    if type == 'xavier_uniform':\n",
    "        initial = xavier_initializer(uniform=True, dtype=tf.float32)\n",
    "    elif type == 'xavier_normal':\n",
    "        initial = xavier_initializer(uniform=False, dtype=tf.float32)\n",
    "    elif type == 'he_normal':\n",
    "        initial = variance_scaling_initializer(uniform=False, factor=2.0, mode='FAN_IN', dtype=tf.float32)\n",
    "    elif type == 'he_uniform':\n",
    "        initial = variance_scaling_initializer(uniform=True, factor=2.0, mode='FAN_IN', dtype=tf.float32)\n",
    "    elif type == 'caffe_uniform':\n",
    "        initial = variance_scaling_initializer(uniform=True, factor=1.0, mode='FAN_IN', dtype=tf.float32)\n",
    "    elif type == 'simple':\n",
    "        stddev = kwargs.get('stddev', 0.02)\n",
    "        initial = tf.truncated_normal(shape, stddev=stddev, dtype=tf.float32)\n",
    "        initialise_from_constant = True\n",
    "    elif type == 'bilinear':\n",
    "        weights = _bilinear_upsample_weights(shape)\n",
    "        initial = tf.constant(weights, shape=shape, dtype=tf.float32)\n",
    "        initialise_from_constant = True\n",
    "    else:\n",
    "        raise ValueError('Unknown initialisation requested: %s' % type)\n",
    "\n",
    "    if name is None:  # This keeps to option open to use unnamed Variables\n",
    "        weight = tf.Variable(initial)\n",
    "    else:\n",
    "        if initialise_from_constant:\n",
    "            weight = tf.get_variable(name, initializer=initial)\n",
    "        else:\n",
    "            weight = tf.get_variable(name, shape=shape, initializer=initial)\n",
    "    if regularize:\n",
    "        tf.add_to_collection('weight_variables', weight)\n",
    "    return weight \n",
    "\n",
    "def Network(number , X , dims , dropoutRate , w_init, activation) :\n",
    "    with tf.variable_scope(f\"Network_{number}\", reuse = tf.AUTO_REUSE):\n",
    "        for idx , h_dim in enumerate(dims) :\n",
    "            if idx == 0 :    \n",
    "                TOTAL_DIM = X.get_shape().as_list()[1]\n",
    "                Weight =get_weight_variable(shape = [TOTAL_DIM , h_dim],\n",
    "                                            name=f\"Weight{idx}\",\n",
    "                                            type=w_init, regularize=True)\n",
    "                Bias = tf.get_variable(f\"Bias{idx}\",\n",
    "                                       shape = [h_dim] , dtype = tf.float32 , \n",
    "                                       initializer = tf.constant_initializer(0.0))\n",
    "                Layer = activation(tf.matmul( X , Weight) + Bias)\n",
    "                Layer = tf.contrib.nn.alpha_dropout(Layer , dropoutRate ) \n",
    "            else :\n",
    "                Weight =get_weight_variable(shape = [dims[idx-1] ,h_dim ], \n",
    "                                            name=f\"Weight{idx}\",\n",
    "                                            type=w_init, regularize=True)\n",
    "                Bias = tf.get_variable(f\"Bias{idx}\",\n",
    "                                       shape = [h_dim] , dtype = tf.float32 , \n",
    "                                       initializer = tf.constant_initializer(0.0))\n",
    "                Layer = tf.matmul( Layer , Weight) + Bias\n",
    "                if len(dims) == idx+1 :pass\n",
    "                else : \n",
    "                    Layer = activation(Layer)\n",
    "                    Layer = tf.contrib.nn.alpha_dropout(Layer , dropoutRate ) \n",
    "            tf.summary.histogram(f\"Weight{idx}\", Weight)\n",
    "            tf.summary.histogram(f\"Bias{idx}\", Bias)\n",
    "    return Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/home/advice/Python/SR/Data/income_evaluation.csv\")\n",
    "objcol = data.select_dtypes(\"object\").columns.tolist()\n",
    "data[objcol] = data[objcol].astype(\"category\")\n",
    "data.columns = [i.strip() for i in data.columns.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"income\"] = data[\"income\"].cat.codes\n",
    "target = data.pop(\"income\")\n",
    "num_col = data.select_dtypes(\"int\").columns.tolist()\n",
    "cat_col = data.select_dtypes(\"category\").columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age               0\n",
       "workclass         0\n",
       "fnlwgt            0\n",
       "education         0\n",
       "education-num     0\n",
       "marital-status    0\n",
       "occupation        0\n",
       "relationship      0\n",
       "race              0\n",
       "sex               0\n",
       "capital-gain      0\n",
       "capital-loss      0\n",
       "hours-per-week    0\n",
       "native-country    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "Train_X , Test_X , Train_y , Test_y =\\\n",
    "train_test_split(data , target , \n",
    "                 test_size = 0.3, \n",
    "                 stratify =target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3266</td>\n",
       "      <td>30</td>\n",
       "      <td>Private</td>\n",
       "      <td>186269</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6192</td>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>258888</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5109</td>\n",
       "      <td>52</td>\n",
       "      <td>Private</td>\n",
       "      <td>236180</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-spouse-absent</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18922</td>\n",
       "      <td>34</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>236415</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5004</td>\n",
       "      <td>36</td>\n",
       "      <td>Private</td>\n",
       "      <td>62346</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age   workclass  fnlwgt      education  education-num  \\\n",
       "3266    30     Private  186269      Bachelors             13   \n",
       "6192    38     Private  258888   Some-college             10   \n",
       "5109    52     Private  236180      Bachelors             13   \n",
       "18922   34   Local-gov  236415   Some-college             10   \n",
       "5004    36     Private   62346        HS-grad              9   \n",
       "\n",
       "               marital-status      occupation    relationship    race  \\\n",
       "3266       Married-civ-spouse    Tech-support         Husband   White   \n",
       "6192       Married-civ-spouse    Adm-clerical            Wife   White   \n",
       "5109    Married-spouse-absent   Other-service   Not-in-family   White   \n",
       "18922           Never-married    Adm-clerical       Unmarried   White   \n",
       "5004       Married-civ-spouse    Craft-repair         Husband   Black   \n",
       "\n",
       "           sex  capital-gain  capital-loss  hours-per-week  native-country  \n",
       "3266      Male             0             0              40   United-States  \n",
       "6192    Female             0             0              35   United-States  \n",
       "5109      Male             0             0              50   United-States  \n",
       "18922   Female             0             0              18   United-States  \n",
       "5004      Male             0             0              40   United-States  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workclass, 9==9==9?\n",
      "education, 16==16==16?\n",
      "marital-status, 7==7==7?\n",
      "occupation, 15==15==15?\n",
      "relationship, 6==6==6?\n",
      "race, 5==5==5?\n",
      "sex, 2==2==2?\n",
      "native-country, 42==41==41?\n",
      "===============\n",
      "Warning! Check : native-country\n",
      "Train Need Category : set()\n",
      "Test Need Category : {' Holand-Netherlands'}\n"
     ]
    }
   ],
   "source": [
    "for col in cat_col :\n",
    "    tr_n = set(Train_X[col].unique()) \n",
    "    te_n = set(Test_X[col].unique()) \n",
    "    intersect = tr_n & te_n\n",
    "    print(f\"{col}, {len(tr_n)}=={len(te_n)}=={len(intersect)}?\")\n",
    "    if len(tr_n) != len(te_n) :\n",
    "        te_need = tr_n.difference(te_n)\n",
    "        tr_need = te_n.difference(tr_n)\n",
    "        print(\"=\"*15)\n",
    "        print(f\"Warning! Check : {col}\")\n",
    "        print(f\"Train Need Category : {tr_need}\")\n",
    "        print(f\"Test Need Category : {te_need}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workclass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/root/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/root/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "education\n",
      "marital-status\n",
      "occupation\n",
      "relationship\n",
      "race\n",
      "sex\n",
      "native-country\n"
     ]
    }
   ],
   "source": [
    "LabelEncoding = {}\n",
    "for col in cat_col :\n",
    "    print(col)\n",
    "    encoding = LabelEncoder()\n",
    "    category = list(set(list(Train_X[col].unique()) + [\"Unknown\"]))\n",
    "    encoding.fit(category)\n",
    "    Train_X[col] = Train_X[col].cat.add_categories('Unknown')\n",
    "    Train_X[col] = Train_X[col].fillna('Unknown')\n",
    "    Train_X[col] = encoding.transform(Train_X[col])\n",
    "    LabelEncoding[col] = encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "0.022764205932617188초\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "start = time()\n",
    "change = {}\n",
    "for col in cat_col :\n",
    "    change[col] = {}\n",
    "    LABLEncoder = LabelEncoding[col]\n",
    "    unknownlabel = set(Test_X[col].unique()).difference(set(LABLEncoder.classes_))\n",
    "    c = dict(zip(unknownlabel , [np.nan] * len(unknownlabel)))\n",
    "    print(c)\n",
    "    c[np.nan] = 'Unknown'\n",
    "    change[col] = c\n",
    "    \n",
    "print(\"{}초\".format(time()- start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workclass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/root/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "education\n",
      "marital-status\n",
      "occupation\n",
      "relationship\n",
      "race\n",
      "sex\n",
      "native-country\n"
     ]
    }
   ],
   "source": [
    "for col in cat_col :\n",
    "    print(col)\n",
    "    LABLEncoder = LabelEncoding[col]\n",
    "    unknownlabel = set(Test_X[col].unique()).difference(set(LABLEncoder.classes_))\n",
    "    c = dict(zip(unknownlabel , [np.nan] * len(unknownlabel)))\n",
    "    c[np.nan] = 'Unknown'\n",
    "    Test_X[col] = Test_X[col].replace(c)   \n",
    "    Test_X[col] = LABLEncoder.transform(Test_X[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_X = Train_X.astype(np.float32)\n",
    "Test_X = Test_X.astype(np.float32)\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "numeric_features = num_col \n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())])\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features)])\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),])\n",
    "clf.fit(Train_X)\n",
    "Train_X[num_col] = clf.transform(Train_X)\n",
    "Test_X[num_col] = clf.transform(Test_X)\n",
    "#train_X[numcol] = imp_mean.transform(train_X[numcol])\n",
    "#test_X[numcol] = imp_mean.transform(test_X[numcol])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 5, 6, 7, 8, 9, 13]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totalcol = data.columns.tolist()\n",
    "objinfo = [idx for idx , col in enumerate(totalcol) if col in cat_col ]\n",
    "objinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 10, 3: 17, 5: 8, 6: 16, 7: 7, 8: 6, 9: 3, 13: 43}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objdict = {}\n",
    "for i in objinfo :\n",
    "    column = totalcol[i]\n",
    "    objdict[i] = len(LabelEncoding[column].classes_)\n",
    "objdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_dim = Train_X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'Placeholder:0' shape=(?, 14) dtype=float32>,\n",
       " <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=float32>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "batch_size = tf.placeholder(tf.int64, name=\"Batchsize\")\n",
    "X =  tf.placeholder(tf.float32 , shape = [None , total_dim])\n",
    "y = tf.placeholder(tf.float32 , [None])\n",
    "dropoutRate = tf.placeholder(tf.float32, name =\"dropoutRate\")\n",
    "InputdropoutRate = tf.placeholder(tf.float32, name =\"InputdropoutRate\")\n",
    "#y = tf.string_to_number(y)\n",
    "X , y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'workclass',\n",
       " 'fnlwgt',\n",
       " 'education',\n",
       " 'education-num',\n",
       " 'marital-status',\n",
       " 'occupation',\n",
       " 'relationship',\n",
       " 'race',\n",
       " 'sex',\n",
       " 'capital-gain',\n",
       " 'capital-loss',\n",
       " 'hours-per-week',\n",
       " 'native-country']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totalcol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3266     4.0\n",
       "6192     4.0\n",
       "5109     4.0\n",
       "18922    2.0\n",
       "5004     4.0\n",
       "Name: workclass, dtype: float32"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_X[cat_col[0]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ' ?',\n",
       " 1: ' Federal-gov',\n",
       " 2: ' Local-gov',\n",
       " 3: ' Never-worked',\n",
       " 4: ' Private',\n",
       " 5: ' Self-emp-inc',\n",
       " 6: ' Self-emp-not-inc',\n",
       " 7: ' State-gov',\n",
       " 8: ' Without-pay',\n",
       " 9: 'Unknown'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(zip(np.arange(len(LabelEncoding[cat_col[0]].classes_)).tolist() , \n",
    "         LabelEncoding[cat_col[0]].classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EmbeddingLayer(X , objdict , inputratio ,totalcol ) :\n",
    "    inputs = []\n",
    "    for idx , key in enumerate(totalcol) :\n",
    "        split = tf.slice(X , [0 , idx ] ,[-1 , 1 ] )\n",
    "        if idx in objdict :\n",
    "            category_n = objdict[idx]\n",
    "            Cat = emb(split , category_n , 4 , inputratio , key)\n",
    "            inputs.append(Cat)\n",
    "        else :\n",
    "            inputs.append(split)\n",
    "    concatenated_layer = tf.concat(inputs, axis=1, name='concatenate') \n",
    "    return concatenated_layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category : workclass\n",
      "[workclass] Onehot Shape : [10] --> Embedding Shape : [5] \n",
      "Category : education\n",
      "[education] Onehot Shape : [17] --> Embedding Shape : [8] \n",
      "Category : marital-status\n",
      "[marital-status] Onehot Shape : [8] --> Embedding Shape : [4] \n",
      "Category : occupation\n",
      "[occupation] Onehot Shape : [16] --> Embedding Shape : [8] \n",
      "Category : relationship\n",
      "[relationship] Onehot Shape : [7] --> Embedding Shape : [3] \n",
      "Category : race\n",
      "[race] Onehot Shape : [6] --> Embedding Shape : [3] \n",
      "Category : sex\n",
      "[sex] Onehot Shape : [3]\n",
      "Category : native-country\n",
      "[native-country] Onehot Shape : [43] --> Embedding Shape : [21] \n"
     ]
    }
   ],
   "source": [
    "TransformX = tf_feature(X , cat_col , objdict , InputdropoutRate, totalcol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(61)])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TransformX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_dim = len(np.unique(Train_y))\n",
    "target_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Network_1/add_3:0\", dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "dims = [40 , 20, 10 , target_dim]\n",
    "init = \"he_normal\"\n",
    "activation = tf.nn.selu\n",
    "Logit = Network(number= 1 ,\n",
    "                X = TransformX , \n",
    "                dims = dims , \n",
    "                dropoutRate=dropoutRate,\n",
    "                w_init = init,\n",
    "                activation = activation)\n",
    "print(Logit)\n",
    "Probs = tf.nn.softmax(Logit)\n",
    "target_dim = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Network_1/add_3:0\", dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(Logit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
      "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: TITAN X (Pascal), pci bus id: 0000:04:00.0, compute capability: 6.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config=tf.ConfigProto(log_device_placement=True)\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config = config)\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
      "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: TITAN X (Pascal), pci bus id: 0000:04:00.0, compute capability: 6.1\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.632696</td>\n",
       "      <td>0.163362</td>\n",
       "      <td>0.08364</td>\n",
       "      <td>0.06562</td>\n",
       "      <td>-0.062301</td>\n",
       "      <td>0.033525</td>\n",
       "      <td>-0.037268</td>\n",
       "      <td>0.150841</td>\n",
       "      <td>0.070555</td>\n",
       "      <td>-0.040634</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079562</td>\n",
       "      <td>-0.060568</td>\n",
       "      <td>-0.073257</td>\n",
       "      <td>-0.000635</td>\n",
       "      <td>0.164677</td>\n",
       "      <td>-0.13292</td>\n",
       "      <td>0.01427</td>\n",
       "      <td>-0.147333</td>\n",
       "      <td>0.066904</td>\n",
       "      <td>-0.001157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1        2        3         4         5         6   \\\n",
       "0 -0.632696  0.163362  0.08364  0.06562 -0.062301  0.033525 -0.037268   \n",
       "\n",
       "         7         8         9   ...        51        52        53        54  \\\n",
       "0  0.150841  0.070555 -0.040634  ...  0.079562 -0.060568 -0.073257 -0.000635   \n",
       "\n",
       "         55       56       57        58        59        60  \n",
       "0  0.164677 -0.13292  0.01427 -0.147333  0.066904 -0.001157  \n",
       "\n",
       "[1 rows x 61 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config=tf.ConfigProto(log_device_placement=True)\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config = config)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "pd.DataFrame(sess.run(TransformX , \n",
    "                      feed_dict ={ X : Train_X.head(1).values ,\n",
    "                                  InputdropoutRate : 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.300647</td>\n",
       "      <td>-1.483904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1\n",
       "0  0.300647 -1.483904"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(sess.run(Logit , \n",
    "                      feed_dict ={ X : Train_X.head(1).values ,\n",
    "                                  InputdropoutRate : 0.8 ,\n",
    "                                  dropoutRate : 0.8}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cass-Balanced Loss Based on Effective Number of Samples\n",
    "\n",
    "\n",
    "### [paper](https://arxiv.org/abs/1901.05555)\n",
    "\n",
    "\n",
    "### [code](https://github.com/richardaecn/class-balanced-loss/blob/master/src/cifar_main.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.losses import Reduction\n",
    "no_of_classes = 2\n",
    "beta = 0.9\n",
    "gamma = 2.0\n",
    "alpha = 1.0\n",
    "y_one_hot = tf.add(alpha* tf.one_hot( tf.cast(y , tf.int32), \n",
    "                                     depth=target_dim) ,(1-alpha) / target_dim)\n",
    "\n",
    "samples_per_cls = tf.transpose(tf.reduce_sum(y_one_hot, axis = 0 ))\n",
    "pw = tf.pow(beta, samples_per_cls)\n",
    "effective_num = 1.0 - tf.pow(beta, samples_per_cls)\n",
    "effective_num = tf.reshape(effective_num,shape=(-1,no_of_classes))\n",
    "weights = (1.0 - beta) / effective_num\n",
    "weights= tf.div(weights , tf.reduce_sum(weights) * no_of_classes)\n",
    "weights = weights * y_one_hot\n",
    "weights = tf.reduce_sum(weights, axis = 1)\n",
    "weights = tf.expand_dims(weights , axis = 1)\n",
    "weights = tf.tile(weights, [1, no_of_classes])\n",
    "WCE = tf.losses.softmax_cross_entropy(onehot_labels= y_one_hot , \n",
    "                                      logits= Logit , \n",
    "                                      weights= tf.reduce_mean(weights, axis=1),\n",
    "                                      label_smoothing= 0.95,\n",
    "                                      reduction= Reduction.MEAN\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(tf.pow(beta, samples_per_cls) , \n",
    "         feed_dict ={X : Train_X.values ,\n",
    "                     y : Train_y.values , \n",
    "                     InputdropoutRate : 0.9 ,\n",
    "                           batch_size : 20 , \n",
    "                           dropoutRate : 0.8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import numpy as np\n",
    "# import torch.nn.functional as F\n",
    "# no_of_classes = 2\n",
    "# logits = torch.rand(10,no_of_classes).float()\n",
    "# labels = torch.randint(0,no_of_classes, size = (10,))\n",
    "# beta = 0.9999\n",
    "# gamma = 2.0\n",
    "# samples_per_cls = [10,1]\n",
    "# effective_num = 1.0 - np.power(beta, samples_per_cls)\n",
    "# weights = (1.0 - beta) / np.array(effective_num)\n",
    "# weights = weights / np.sum(weights) * no_of_classes\n",
    "# labels_one_hot = F.one_hot(labels, no_of_classes).float()\n",
    "# weights = torch.tensor(weights).float()\n",
    "# weights = weights.unsqueeze(0)\n",
    "# weights = weights.repeat(labels_one_hot.shape[0],1) * labels_one_hot\n",
    "# weights = weights.sum(1)\n",
    "# weights = weights.unsqueeze(1)\n",
    "# weights = weights.repeat(1,no_of_classes)\n",
    "# print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Loss = tf.reduce_mean(WCE)\n",
    "vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,scope=\"Network\")\n",
    "WEIGHTS = tf.get_collection(\"weight_variables\")\n",
    "import re \n",
    "L2 = []\n",
    "for v in WEIGHTS :\n",
    "    L2.append(tf.nn.l2_loss(v))\n",
    "Loss += tf.add_n(L2)  * 0.0001\n",
    "l1_regularizer = tf.contrib.layers.l1_regularizer(scale=0.005, scope=None)\n",
    "regularization_penalty = tf.contrib.layers.apply_regularization(l1_regularizer, WEIGHTS )\n",
    "Loss += regularization_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = RAdamOptimizer(learning_rate= 2e-5, beta1 = 0.9 ,)\n",
    "solver = solver.minimize(Loss ,var_list = vars )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
      "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: TITAN X (Pascal), pci bus id: 0000:04:00.0, compute capability: 6.1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.6/site-packages/pandas/core/series.py:1143: FutureWarning:\n",
      "\n",
      "\n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_Loss_ = []\n",
    "Epoch= 50000\n",
    "mb_size = 500\n",
    "print(\"Train\")\n",
    "log = logging.getLogger('TF_log')\n",
    "log.setLevel(logging.DEBUG)\n",
    "fileHandler = logging.FileHandler(os.path.join(ResultPath,'tf_log.txt') , mode= \"w\")\n",
    "log.addHandler(fileHandler)\n",
    "\n",
    "config=tf.ConfigProto(log_device_placement=True)\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config = config)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "_Loss_ = []\n",
    "_Epoch_ = []\n",
    "_Epoch2_ = [0]\n",
    "_trAUC_ , _teAUC_ = [0] , [0]\n",
    "\n",
    "\n",
    "for epoch in range(Epoch) :\n",
    "    idx = list(np.random.permutation(len(Train_X)))\n",
    "    if (epoch > 0 ) & (epoch > 100) :\n",
    "        #idx = idx + BoostingList\n",
    "        idx = list(np.random.permutation(idx))\n",
    "        mb_size = 1000\n",
    "    else : \n",
    "        mb_size = 500\n",
    "    XX = Train_X.iloc[idx, : ].values\n",
    "    YY = Train_y[idx]\n",
    "    batch_iter = int(len(XX) / mb_size)\n",
    "    _Loss2_ = []\n",
    "    for idx in range(batch_iter) :\n",
    "        X_mb = XX[idx*mb_size:(idx+1)*mb_size]\n",
    "        Y_mb = YY[idx*mb_size:(idx+1)*mb_size]\n",
    "        Feed = {X : X_mb ,\n",
    "                y : Y_mb , \n",
    "                InputdropoutRate : 0.8 ,\n",
    "                dropoutRate : 0.8\n",
    "               }\n",
    "        _ , LOSS  = sess.run([solver , Loss] , feed_dict= Feed)\n",
    "        _Loss2_.append(LOSS)\n",
    "    _Loss_.append(np.mean(_Loss2_))\n",
    "    _Epoch_.append(epoch)\n",
    "    if (epoch > 0 ) & (epoch % 100 == 0) :\n",
    "        Feed = { X : Train_X.values ,\n",
    "                InputdropoutRate : 0.8 ,\n",
    "                dropoutRate : 0.8\n",
    "               }\n",
    "        probs  = sess.run(Probs , feed_dict= Feed)\n",
    "        trainDD = pd.DataFrame([Train_y ,probs[:,1]],\n",
    "                          index = [\"t\",\"prob\"]).T\n",
    "        ### Target 1 Boosting List\n",
    "        DD2 = trainDD[(trainDD.t == 1) & (trainDD.prob <0.5)]\n",
    "        BoostingList = 1 * DD2.index.tolist()\n",
    "        msg = \"Epoch : {}  Boosting List : {}\".\\\n",
    "              format(epoch,len(DD2.index.tolist()))\n",
    "        log.info(msg)\n",
    "    if (epoch > 0)  & (epoch % 100 == 0) :\n",
    "        Feed = { X : Train_X.values ,\n",
    "                InputdropoutRate : 0.8 ,\n",
    "                dropoutRate : 0.8\n",
    "               }\n",
    "        clear_output()\n",
    "        tr_real_target = np.squeeze(Train_y.values)\n",
    "        tr_probs  = sess.run(Probs , feed_dict= Feed)\n",
    "        tr_AUC = roc_auc_score(tr_real_target ,  tr_probs[:,1])\n",
    "        trainDD = pd.DataFrame([Train_y.values ,probs[:,1]],\n",
    "                          index = [\"t\",\"prob\"]).T\n",
    "        ####################################################\n",
    "        Feed = {X : Test_X.values  ,\n",
    "                InputdropoutRate : 0.8 ,\n",
    "                dropoutRate : 0.8\n",
    "           }\n",
    "        te_probs  = sess.run(Probs , feed_dict= Feed)\n",
    "        te_real_target = np.squeeze(Test_y.values)\n",
    "        te_AUC = roc_auc_score(te_real_target , te_probs[:,1])\n",
    "        testDD = pd.DataFrame([te_real_target ,te_probs[:,1]],\n",
    "                          index = [\"t\",\"prob\"]).T\n",
    "        \n",
    "        fig , axes = plt.subplots(nrows=4 ,ncols=2,\n",
    "                  figsize=(15,12) )\n",
    "        plt.subplots_adjust(left=0.05, bottom=0.1, right=0.99, \n",
    "                            top=0.95, wspace=None, hspace=0.5)\n",
    "        ax = axes.flatten()\n",
    "        sns.boxplot(x=\"t\", y=\"prob\", data=trainDD, ax = ax[0])\n",
    "        ax[0].set_title(\"train : {:.3f}\".format(tr_AUC), fontsize= 25)\n",
    "        sns.boxplot(x=\"t\", y=\"prob\", data=testDD, ax = ax[1])\n",
    "        ax[1].set_title(\"test : {:.3f}\".format(te_AUC), fontsize= 25)\n",
    "        skplt.metrics.plot_ks_statistic(Train_y.values, tr_probs , \n",
    "                                        ax = ax[2] , \n",
    "                                        title = \"[Train] KS Static PLOT\")\n",
    "        skplt.metrics.plot_ks_statistic(Test_y.values, te_probs ,\n",
    "                                        ax = ax[3], \n",
    "                                        title = \"[Test] KS Static PLOT\")\n",
    "\n",
    "        ax3 = plt.subplot(413)\n",
    "        plt.subplots_adjust(left=0.05, bottom=0.1, right=0.99, \n",
    "                            top=0.95, wspace=None, hspace=0.7)\n",
    "        ax3.plot(_Epoch_ , _Loss_ )\n",
    "        ax3.set_title(msg, fontsize= 20)\n",
    "        _Epoch2_.append(epoch)\n",
    "        _trAUC_.append(tr_AUC)\n",
    "        _teAUC_.append(te_AUC)\n",
    "        ax4 = plt.subplot(414)\n",
    "        ax4.plot(_Epoch2_ , _trAUC_ , label = \"train auc\")\n",
    "        ax4.plot(_Epoch2_ , _teAUC_ , label = \"test auc\")\n",
    "        ax4.legend()\n",
    "        msg = \"Epoch : {} / AUC | Train : {:.2f} Test : {:.2f}\".format(epoch , \n",
    "                                                               100*tr_AUC ,\n",
    "                                                               100*te_AUC\n",
    "                                                              )\n",
    "        ax4.set_title(msg, fontsize= 20)\n",
    "        savefig = os.path.join(ResultPath,f'plot.{epoch:04d}.png')\n",
    "        plt.savefig(savefig)\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_model(trial = None) :\n",
    "    nodes_1 = trial.suggest_int(\"nodes_1\",30,65)\n",
    "    nodes_2 = trial.suggest_int(\"nodes_2\",30,65)\n",
    "    nodes_3 = trial.suggest_int(\"nodes_3\",10,30)\n",
    "    \n",
    "    init_candidate =\\\n",
    "    [\"xavier_uniform\",\"xavier_normal\", \n",
    "     \"he_normal\", \"he_uniform\",\"caffe_uniform\"]\n",
    "    activate_candidate = \\\n",
    "    [tf.nn.selu, tf_mish , tf.nn.leaky_relu , tf.nn.elu , tf.nn.relu ]\n",
    "    activate_int = [0,1,2,3,4]\n",
    "    \n",
    "    target_n = 2 \n",
    "    init =\\\n",
    "    trial.suggest_categorical('weight_init', init_candidate)\n",
    "    selected =\\\n",
    "    trial.suggest_categorical('activation', activate_int)\n",
    "    activation = activate_candidate[selected]\n",
    "    alpha = trial.suggest_uniform('smoothLabel', 0.7, 0.99)\n",
    "    ##################################################################\n",
    "    tf.reset_default_graph()\n",
    "    batch_size = tf.placeholder(tf.int64, name=\"Batchsize\")\n",
    "    X =  tf.placeholder(tf.float32 , shape = [None , total_dim])\n",
    "    y = tf.placeholder(tf.float32 , [None])\n",
    "    regularizer = tf.placeholder(tf.float32, name =\"regularizer\")\n",
    "    dropoutRate = tf.placeholder(tf.float32, name =\"dropoutRate\")\n",
    "    InputdropoutRate = tf.placeholder(tf.float32, name =\"InputdropoutRate\")\n",
    "    ##################################################################\n",
    "    TransformX = tf_feature(X , cat_col , objdict , InputdropoutRate, totalcol)\n",
    "    dims = [nodes_1 , nodes_2, nodes_3 , target_dim]\n",
    "    print(dims)\n",
    "    Logit = Network(number= trial.number ,\n",
    "                    X = TransformX , \n",
    "                    dims = dims , \n",
    "                    dropoutRate=dropoutRate,\n",
    "                    w_init = init,\n",
    "                    activation = activation)\n",
    "    Probs = tf.nn.softmax(Logit)\n",
    "    yy = tf.one_hot( tf.cast(y , tf.int32), depth=target_dim) \n",
    "    y_one_hot = tf.add(alpha* yy,(1-alpha) / target_dim)\n",
    "    from sklearn.utils.class_weight import compute_class_weight\n",
    "    y_weight_info = compute_class_weight(\n",
    "        class_weight= \"balanced\" , \n",
    "        classes = np.unique(Train_y),\n",
    "        y= np.squeeze(Train_y))\n",
    "\n",
    "    weight = tf.constant([ y_weight_info[1] ] ) #\n",
    "    WCE = tf.nn.weighted_cross_entropy_with_logits(targets = y_one_hot ,\n",
    "                                                   logits = Logit , \n",
    "                                                   pos_weight =  weight)\n",
    "\n",
    "    \n",
    "    Loss = tf.reduce_mean(WCE)\n",
    "    vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,\n",
    "                             scope=f\"Network_{trial.number}\")\n",
    "    WEIGHTS = tf.get_collection(\"weight_variables\")\n",
    "    L2 = []\n",
    "    for v in WEIGHTS :\n",
    "        L2.append(tf.nn.l2_loss(v))\n",
    "    Loss += tf.add_n(L2)  * regularizer\n",
    "    l1_regularizer = tf.contrib.layers.l1_regularizer(scale=0.005, scope=None)\n",
    "    regularization_penalty = tf.contrib.layers.apply_regularization(l1_regularizer, WEIGHTS )\n",
    "    Loss += regularizer * regularization_penalty\n",
    "    kwargs = {}\n",
    "    kwargs['learning_rate'] = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
    "    optimizer = RAdamOptimizer(**kwargs)\n",
    "    solver = optimizer.minimize(Loss ,var_list = vars )\n",
    "\n",
    "    prediction = tf.argmax(Probs, 1)\n",
    "    correct = tf.argmax(y_one_hot, 1)\n",
    "    equality = tf.equal(prediction, correct)\n",
    "    accuracy = tf.reduce_mean(tf.cast(equality, tf.float32))\n",
    "    tf.summary.scalar(f\"Accuracy_{trial.number}\",accuracy)\n",
    "    tf.summary.scalar(f\"Loss_{trial.number}\",Loss)\n",
    "    tf.summary.histogram(f\"Probability_{trial.number}\", Probs)\n",
    "    merged = tf.summary.merge_all()\n",
    "    return [Probs , Loss , solver, \n",
    "            X , y , dropoutRate , InputdropoutRate ,regularizer,\n",
    "            merged]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_auc = 0.0\n",
    "log = logging.getLogger('optuna')\n",
    "log.setLevel(logging.DEBUG)\n",
    "fileHandler = logging.FileHandler(\n",
    "    os.path.join(ResultPath,'optuna_log.txt') , mode= \"w\")\n",
    "log.addHandler(fileHandler)\n",
    "\n",
    "\n",
    "def objective(trial):   \n",
    "    Lists = create_model(trial =trial)\n",
    "    (Probs , Loss , solver, \n",
    "     X , y , dropoutRate , InputdropoutRate , regularizer,\n",
    "     merged\n",
    "    ) = Lists\n",
    "    \n",
    "    if trial.number > 11 :\n",
    "        Epoch = 1000\n",
    "        mb_size = 1000\n",
    "    else :\n",
    "        Epoch = 500\n",
    "        mb_size = 500\n",
    "    config=tf.ConfigProto(log_device_placement=True)\n",
    "    config.gpu_options.allow_growth = True\n",
    "    sess = tf.Session(config = config)\n",
    "    train_writer = tf.summary.FileWriter(os.path.join(ResultPath,\n",
    "                                                      f'train_{trial.number}'),\n",
    "                                         sess.graph)\n",
    "    saver = tf.train.Saver()\n",
    "    config = projector.ProjectorConfig()\n",
    "    mod = sys.modules[__name__]\n",
    "    for cat in cat_col :\n",
    "        if len(LabelEncoding[cat].classes_) < 5 :\n",
    "            continue\n",
    "        index2word_map = dict(zip(np.arange(len(LabelEncoding[cat].classes_)).tolist() , \n",
    "                                 LabelEncoding[cat].classes_))\n",
    "        metadata_file = os.path.join(ResultPath, f'train_{trial.number}', \n",
    "                               f'metadata_{trial.number}_{cat}.tsv') \n",
    "        with open(metadata_file, \"w\") as metadata:\n",
    "            metadata.write('Name\\tClass\\n')\n",
    "            for k, v in index2word_map.items():\n",
    "                metadata.write('%s\\t%d\\n' % (v, k))\n",
    "        embedding = config.embeddings.add()\n",
    "        embedding.tensor_name = getattr(mod,  f'embedding_{cat}').name\n",
    "        # Link this tensor to its metadata file (e.g. labels).\n",
    "        embedding.metadata_path = metadata_file\n",
    "    projector.visualize_embeddings(train_writer, config)\n",
    "\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    _Loss_ = []\n",
    "    _Epoch_ = []\n",
    "    _Epoch2_ = [0]\n",
    "    _trAUC_ , _teAUC_ = [0] , [0]\n",
    "    for epoch in range(Epoch) :\n",
    "        if epoch < 100 :\n",
    "            regularizer_rate = 1e-5\n",
    "        elif epoch < 200 :\n",
    "            regularizer_rate = 1e-4\n",
    "        elif epoch < 400 :\n",
    "            regularizer_rate = 1e-3\n",
    "        elif epoch < 800 :\n",
    "            regularizer_rate = 1e-2\n",
    "        idx = list(np.random.permutation(len(Train_X)))\n",
    "        XX = Train_X.iloc[idx, : ].values\n",
    "        YY = Train_y[idx]\n",
    "        batch_iter = int(len(XX) / mb_size)\n",
    "        _Loss2_ = []\n",
    "        for idx in range(batch_iter) :\n",
    "            X_mb = XX[idx*mb_size:(idx+1)*mb_size]\n",
    "            Y_mb = YY[idx*mb_size:(idx+1)*mb_size]\n",
    "            Feed = {X : X_mb ,\n",
    "                    y : Y_mb , \n",
    "                    regularizer : regularizer_rate,\n",
    "                    InputdropoutRate : 0.8 ,\n",
    "                    dropoutRate : 0.8\n",
    "                   }\n",
    "            _ , LOSS  = sess.run([solver , Loss] , feed_dict= Feed)\n",
    "            _Loss2_.append(LOSS)\n",
    "        _Loss_.append(np.mean(_Loss2_))\n",
    "        _Epoch_.append(epoch)\n",
    "        if epoch % 100 == 0 :\n",
    "            saver.save(sess, os.path.join(ResultPath, f'train_{trial.number}', \"model.ckpt\" ), epoch)\n",
    "            Feed = {X : Test_X.values  ,\n",
    "                    y : Test_y.values ,\n",
    "                    regularizer : regularizer_rate,\n",
    "                    InputdropoutRate : 0.8 ,\n",
    "                    dropoutRate : 0.8,\n",
    "                   }\n",
    "            summary = sess.run( merged ,feed_dict= Feed)\n",
    "            train_writer.add_summary(summary, epoch)\n",
    "            \n",
    "    train_writer.close()\n",
    "    Feed = {X : Test_X.values  ,\n",
    "                InputdropoutRate : 0.8 ,\n",
    "                dropoutRate : 0.8\n",
    "           }\n",
    "    te_probs  = sess.run(Probs , feed_dict= Feed)\n",
    "    te_real_target = np.squeeze(Test_y.values)\n",
    "    AUC = roc_auc_score(te_real_target , te_probs[:,1])\n",
    "    global best_auc\n",
    "    if best_auc < AUC :\n",
    "        log.info(\"Try : {}, {} < {}\".format(trial.number , best_auc ,AUC))\n",
    "        best_auc= AUC\n",
    "    clear_output()\n",
    "    return AUC\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category : workclass\n",
      "Category : workclass\n",
      "Category : workclass\n",
      "Category : workclassCategory : workclass\n",
      "Category : workclassCategory : workclassCategory : workclass\n",
      "\n",
      "\n",
      "\n",
      "Category : workclassCategory : workclass\n",
      "\n",
      "[workclass] Onehot Shape : [10] --> Embedding Shape : [5] \n",
      "[workclass] Onehot Shape : [10] --> Embedding Shape : [5] \n",
      "Category : education\n",
      "Category : education\n",
      "[workclass] Onehot Shape : [10] --> Embedding Shape : [5] [workclass] Onehot Shape : [10] --> Embedding Shape : [5] \n",
      "\n",
      "[workclass] Onehot Shape : [10] --> Embedding Shape : [5] \n",
      "[workclass] Onehot Shape : [10] --> Embedding Shape : [5] \n",
      "[workclass] Onehot Shape : [10] --> Embedding Shape : [5] Category : educationCategory : education\n",
      "\n",
      "\n",
      "[workclass] Onehot Shape : [10] --> Embedding Shape : [5] [workclass] Onehot Shape : [10] --> Embedding Shape : [5] Category : education\n",
      "\n",
      "\n",
      "[workclass] Onehot Shape : [10] --> Embedding Shape : [5] Category : educationCategory : education\n",
      "\n",
      "\n",
      "[education] Onehot Shape : [17] --> Embedding Shape : [8] Category : education\n",
      "\n",
      "[education] Onehot Shape : [17] --> Embedding Shape : [8] Category : education\n",
      "\n",
      "Category : education\n",
      "Category : marital-status\n",
      "Category : marital-status\n",
      "[education] Onehot Shape : [17] --> Embedding Shape : [8] [education] Onehot Shape : [17] --> Embedding Shape : [8] \n",
      "\n",
      "[education] Onehot Shape : [17] --> Embedding Shape : [8] \n",
      "[education] Onehot Shape : [17] --> Embedding Shape : [8] [education] Onehot Shape : [17] --> Embedding Shape : [8] \n",
      "Category : marital-status\n",
      "\n",
      "Category : marital-status\n",
      "Category : marital-status\n",
      "[education] Onehot Shape : [17] --> Embedding Shape : [8] \n",
      "Category : marital-status\n",
      "[marital-status] Onehot Shape : [8] --> Embedding Shape : [4] Category : marital-status[education] Onehot Shape : [17] --> Embedding Shape : [8] \n",
      "\n",
      "\n",
      "Category : marital-statusCategory : occupation\n",
      "\n",
      "[marital-status] Onehot Shape : [8] --> Embedding Shape : [4] [education] Onehot Shape : [17] --> Embedding Shape : [8] \n",
      "\n",
      "Category : marital-status\n",
      "Category : marital-status\n",
      "Category : occupation\n",
      "[marital-status] Onehot Shape : [8] --> Embedding Shape : [4] \n",
      "Category : occupation[marital-status] Onehot Shape : [8] --> Embedding Shape : [4] \n",
      "\n",
      "[marital-status] Onehot Shape : [8] --> Embedding Shape : [4] \n",
      "Category : occupation\n",
      "[marital-status] Onehot Shape : [8] --> Embedding Shape : [4] \n",
      "[marital-status] Onehot Shape : [8] --> Embedding Shape : [4] [marital-status] Onehot Shape : [8] --> Embedding Shape : [4] Category : occupation\n",
      "Category : occupation\n",
      "\n",
      "[marital-status] Onehot Shape : [8] --> Embedding Shape : [4] Category : occupation\n",
      "\n",
      "\n",
      "[occupation] Onehot Shape : [16] --> Embedding Shape : [8] Category : occupation\n",
      "Category : occupation\n",
      "[occupation] Onehot Shape : [16] --> Embedding Shape : [8] [marital-status] Onehot Shape : [8] --> Embedding Shape : [4] \n",
      "\n",
      "\n",
      "Category : relationshipCategory : relationship\n",
      "\n",
      "Category : occupation\n",
      "[occupation] Onehot Shape : [16] --> Embedding Shape : [8] \n",
      "[occupation] Onehot Shape : [16] --> Embedding Shape : [8] \n",
      "Category : relationship[occupation] Onehot Shape : [16] --> Embedding Shape : [8] \n",
      "\n",
      "Category : relationship\n",
      "[occupation] Onehot Shape : [16] --> Embedding Shape : [8] \n",
      "[occupation] Onehot Shape : [16] --> Embedding Shape : [8] \n",
      "Category : relationship\n",
      "Category : relationship[occupation] Onehot Shape : [16] --> Embedding Shape : [8] [occupation] Onehot Shape : [16] --> Embedding Shape : [8] \n",
      "\n",
      "Category : relationship\n",
      "[relationship] Onehot Shape : [7] --> Embedding Shape : [3] \n",
      "\n",
      "[relationship] Onehot Shape : [7] --> Embedding Shape : [3] Category : relationshipCategory : relationship\n",
      "\n",
      "\n",
      "[occupation] Onehot Shape : [16] --> Embedding Shape : [8] Category : race\n",
      "\n",
      "Category : race\n",
      "Category : relationship\n",
      "[relationship] Onehot Shape : [7] --> Embedding Shape : [3] \n",
      "[relationship] Onehot Shape : [7] --> Embedding Shape : [3] [relationship] Onehot Shape : [7] --> Embedding Shape : [3] \n",
      "\n",
      "Category : race\n",
      "Category : race\n",
      "Category : race[relationship] Onehot Shape : [7] --> Embedding Shape : [3] \n",
      "\n",
      "[relationship] Onehot Shape : [7] --> Embedding Shape : [3] Category : race\n",
      "\n",
      "[relationship] Onehot Shape : [7] --> Embedding Shape : [3] \n",
      "[race] Onehot Shape : [6] --> Embedding Shape : [3] Category : race[race] Onehot Shape : [6] --> Embedding Shape : [3] [relationship] Onehot Shape : [7] --> Embedding Shape : [3] \n",
      "\n",
      "\n",
      "Category : race\n",
      "Category : sex\n",
      "Category : sexCategory : race\n",
      "\n",
      "\n",
      "[relationship] Onehot Shape : [7] --> Embedding Shape : [3] \n",
      "[sex] Onehot Shape : [3]Category : race\n",
      "\n",
      "[sex] Onehot Shape : [3]\n",
      "[race] Onehot Shape : [6] --> Embedding Shape : [3] \n",
      "Category : native-country[race] Onehot Shape : [6] --> Embedding Shape : [3] \n",
      "Category : native-country[race] Onehot Shape : [6] --> Embedding Shape : [3] \n",
      "\n",
      "\n",
      "Category : sexCategory : sex\n",
      "\n",
      "Category : sex\n",
      "[race] Onehot Shape : [6] --> Embedding Shape : [3] \n",
      "[race] Onehot Shape : [6] --> Embedding Shape : [3] \n",
      "[sex] Onehot Shape : [3]Category : sex[sex] Onehot Shape : [3]\n",
      "\n",
      "\n",
      "Category : sex[race] Onehot Shape : [6] --> Embedding Shape : [3] \n",
      "[sex] Onehot Shape : [3][race] Onehot Shape : [6] --> Embedding Shape : [3] \n",
      "\n",
      "\n",
      "Category : sex[sex] Onehot Shape : [3]\n",
      "\n",
      "[race] Onehot Shape : [6] --> Embedding Shape : [3] Category : sex\n",
      "[sex] Onehot Shape : [3]Category : native-country\n",
      "\n",
      "\n",
      "Category : sexCategory : native-country[sex] Onehot Shape : [3]\n",
      "\n",
      "Category : native-country\n",
      "\n",
      "[sex] Onehot Shape : [3]\n",
      "Category : native-country[native-country] Onehot Shape : [43] --> Embedding Shape : [21] \n",
      "\n",
      "[native-country] Onehot Shape : [43] --> Embedding Shape : [21] [sex] Onehot Shape : [3]Category : native-country\n",
      "\n",
      "\n",
      "[33, 64, 23, 2]\n",
      "[61, 57, 25, 2]\n",
      "Category : native-country\n",
      "Category : native-country\n",
      "Category : native-country\n",
      "[native-country] Onehot Shape : [43] --> Embedding Shape : [21] \n",
      "[native-country] Onehot Shape : [43] --> Embedding Shape : [21] \n",
      "[native-country] Onehot Shape : [43] --> Embedding Shape : [21] \n",
      "[43, 61, 21, 2][64, 41, 29, 2][native-country] Onehot Shape : [43] --> Embedding Shape : [21] \n",
      "\n",
      "\n",
      "[44, 47, 23, 2]\n",
      "[38, 39, 17, 2][native-country] Onehot Shape : [43] --> Embedding Shape : [21] \n",
      "\n",
      "[native-country] Onehot Shape : [43] --> Embedding Shape : [21] \n",
      "[native-country] Onehot Shape : [43] --> Embedding Shape : [21] [56, 57, 24, 2]\n",
      "[native-country] Onehot Shape : [43] --> Embedding Shape : [21] \n",
      "[32, 62, 23, 2]\n",
      "[55, 30, 30, 2]\n",
      "\n",
      "[41, 47, 18, 2]\n",
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
      "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: TITAN X (Pascal), pci bus id: 0000:04:00.0, compute capability: 6.1\n",
      "\n",
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
      "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: TITAN X (Pascal), pci bus id: 0000:04:00.0, compute capability: 6.1\n",
      "\n",
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
      "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: TITAN X (Pascal), pci bus id: 0000:04:00.0, compute capability: 6.1\n",
      "\n",
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
      "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: TITAN X (Pascal), pci bus id: 0000:04:00.0, compute capability: 6.1\n",
      "\n",
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
      "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: TITAN X (Pascal), pci bus id: 0000:04:00.0, compute capability: 6.1\n",
      "\n",
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
      "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: TITAN X (Pascal), pci bus id: 0000:04:00.0, compute capability: 6.1\n",
      "\n",
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
      "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: TITAN X (Pascal), pci bus id: 0000:04:00.0, compute capability: 6.1\n",
      "\n",
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
      "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: TITAN X (Pascal), pci bus id: 0000:04:00.0, compute capability: 6.1\n",
      "\n",
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
      "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: TITAN X (Pascal), pci bus id: 0000:04:00.0, compute capability: 6.1\n",
      "\n",
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
      "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: TITAN X (Pascal), pci bus id: 0000:04:00.0, compute capability: 6.1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.6/site-packages/pandas/core/series.py:1143: FutureWarning:\n",
      "\n",
      "\n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optuna.logging.enable_propagation()\n",
    "optuna.logging.disable_default_handler()\n",
    "sampler = SkoptSampler(\n",
    "    skopt_kwargs={'n_random_starts':0,\n",
    "                  'acq_func':'EI',\n",
    "                  'acq_func_kwargs': {'xi':0.02, \n",
    "                                      \"x0\" : None, \n",
    "                                      \"y0\" : None}})\n",
    "if __name__ == '__main__':\n",
    "    logging.getLogger().info(\"Start optimization.\")\n",
    "    study = optuna.create_study(direction='maximize',\n",
    "                               sampler = sampler)\n",
    "    study.optimize(objective, \n",
    "                   n_trials=100,\n",
    "                   n_jobs = 10\n",
    "                  )\n",
    "    print('Number of finished trials: ', len(study.trials))\n",
    "\n",
    "    print('Best trial:')\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print('  Value: ', trial.value)\n",
    "\n",
    "    print('  Params: ')\n",
    "    for key, value in trial.params.items():\n",
    "        print('    {}: {}'.format(key, value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
