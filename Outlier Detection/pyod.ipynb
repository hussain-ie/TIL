{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Outlier Dectection Package \n",
    "\n",
    "* https://github.com/yzhao062/pyod/tree/master/examples\n",
    "\n",
    "* https://github.com/yzhao062/pyod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                19264     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 300)               19500     \n",
      "=================================================================\n",
      "Total params: 224,612\n",
      "Trainable params: 224,612\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/30\n",
      "18000/18000 [==============================] - 5s 273us/step - loss: 100.0488 - val_loss: 22.9976\n",
      "Epoch 2/30\n",
      "18000/18000 [==============================] - 4s 226us/step - loss: 13.3334 - val_loss: 8.9761\n",
      "Epoch 3/30\n",
      "18000/18000 [==============================] - 4s 232us/step - loss: 6.7787 - val_loss: 5.8685\n",
      "Epoch 4/30\n",
      "18000/18000 [==============================] - 4s 220us/step - loss: 4.9273 - val_loss: 4.6368\n",
      "Epoch 5/30\n",
      "18000/18000 [==============================] - 4s 231us/step - loss: 3.9885 - val_loss: 3.8720\n",
      "Epoch 6/30\n",
      "18000/18000 [==============================] - 4s 235us/step - loss: 3.4002 - val_loss: 3.3878\n",
      "Epoch 7/30\n",
      "18000/18000 [==============================] - 4s 234us/step - loss: 2.9794 - val_loss: 2.9880\n",
      "Epoch 8/30\n",
      "18000/18000 [==============================] - 4s 228us/step - loss: 2.6492 - val_loss: 2.7028\n",
      "Epoch 9/30\n",
      "18000/18000 [==============================] - 4s 243us/step - loss: 2.3864 - val_loss: 2.4421\n",
      "Epoch 10/30\n",
      "18000/18000 [==============================] - 4s 229us/step - loss: 2.1810 - val_loss: 2.2628\n",
      "Epoch 11/30\n",
      "18000/18000 [==============================] - 4s 229us/step - loss: 1.9986 - val_loss: 2.0953\n",
      "Epoch 12/30\n",
      "18000/18000 [==============================] - 4s 233us/step - loss: 1.8476 - val_loss: 1.9728\n",
      "Epoch 13/30\n",
      "18000/18000 [==============================] - 4s 230us/step - loss: 1.7182 - val_loss: 1.8491\n",
      "Epoch 14/30\n",
      "18000/18000 [==============================] - 4s 235us/step - loss: 1.6114 - val_loss: 1.7685\n",
      "Epoch 15/30\n",
      "18000/18000 [==============================] - 4s 230us/step - loss: 1.5176 - val_loss: 1.6867\n",
      "Epoch 16/30\n",
      "18000/18000 [==============================] - 4s 237us/step - loss: 1.4357 - val_loss: 1.6185\n",
      "Epoch 17/30\n",
      "18000/18000 [==============================] - 4s 231us/step - loss: 1.3655 - val_loss: 1.5557\n",
      "Epoch 18/30\n",
      "18000/18000 [==============================] - 4s 232us/step - loss: 1.3052 - val_loss: 1.5086\n",
      "Epoch 19/30\n",
      "18000/18000 [==============================] - 4s 229us/step - loss: 1.2530 - val_loss: 1.4622\n",
      "Epoch 20/30\n",
      "18000/18000 [==============================] - 4s 238us/step - loss: 1.2083 - val_loss: 1.4239\n",
      "Epoch 21/30\n",
      "18000/18000 [==============================] - 4s 232us/step - loss: 1.1701 - val_loss: 1.3917\n",
      "Epoch 22/30\n",
      "18000/18000 [==============================] - 4s 234us/step - loss: 1.1373 - val_loss: 1.3636\n",
      "Epoch 23/30\n",
      "18000/18000 [==============================] - 4s 233us/step - loss: 1.1097 - val_loss: 1.3400\n",
      "Epoch 24/30\n",
      "18000/18000 [==============================] - 4s 228us/step - loss: 1.0861 - val_loss: 1.3205\n",
      "Epoch 25/30\n",
      "18000/18000 [==============================] - 4s 234us/step - loss: 1.0672 - val_loss: 1.3045\n",
      "Epoch 26/30\n",
      "18000/18000 [==============================] - 4s 231us/step - loss: 1.0512 - val_loss: 1.2907\n",
      "Epoch 27/30\n",
      "18000/18000 [==============================] - 4s 234us/step - loss: 1.0384 - val_loss: 1.2796\n",
      "Epoch 28/30\n",
      "18000/18000 [==============================] - 4s 225us/step - loss: 1.0280 - val_loss: 1.2708\n",
      "Epoch 29/30\n",
      "18000/18000 [==============================] - 4s 228us/step - loss: 1.0198 - val_loss: 1.2637\n",
      "Epoch 30/30\n",
      "18000/18000 [==============================] - 4s 230us/step - loss: 1.0133 - val_loss: 1.2581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/scipy/stats/stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "On Training Data:\n",
      "AutoEncoder ROC:1.0, precision @ rank n:1.0\n",
      "\n",
      "On Test Data:\n",
      "AutoEncoder ROC:1.0, precision @ rank n:1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/scipy/stats/stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n",
      "/usr/local/lib/python3.5/dist-packages/scipy/stats/stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    }
   ],
   "source": [
    "from pyod.models.auto_encoder import AutoEncoder\n",
    "from pyod.utils.data import generate_data\n",
    "from pyod.utils.data import evaluate_print\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    contamination = 0.1  # percentage of outliers\n",
    "    n_train = 20000  # number of training points\n",
    "    n_test = 2000  # number of testing points\n",
    "    n_features = 300  # number of features\n",
    "\n",
    "    # Generate sample data\n",
    "    X_train, y_train, X_test, y_test = \\\n",
    "        generate_data(n_train=n_train,\n",
    "                      n_test=n_test,\n",
    "                      n_features=n_features,\n",
    "                      contamination=contamination,\n",
    "                      random_state=42)\n",
    "\n",
    "    # train AutoEncoder detector\n",
    "    clf_name = 'AutoEncoder'\n",
    "    clf = AutoEncoder(epochs=30, contamination=contamination)\n",
    "    clf.fit(X_train)\n",
    "\n",
    "    # get the prediction labels and outlier scores of the training data\n",
    "    y_train_pred = clf.labels_  # binary labels (0: inliers, 1: outliers)\n",
    "    y_train_scores = clf.decision_scores_  # raw outlier scores\n",
    "\n",
    "    # get the prediction on the test data\n",
    "    y_test_pred = clf.predict(X_test)  # outlier labels (0 or 1)\n",
    "    y_test_scores = clf.decision_function(X_test)  # outlier scores\n",
    "\n",
    "    # evaluate and print the results\n",
    "    print(\"\\nOn Training Data:\")\n",
    "    evaluate_print(clf_name, y_train, y_train_scores)\n",
    "    print(\"\\nOn Test Data:\")\n",
    "    evaluate_print(clf_name, y_test, y_test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
