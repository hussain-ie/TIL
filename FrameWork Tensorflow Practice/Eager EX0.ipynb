{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF Version2를 잘하려면, eager 가 기본이라고 한다.\n",
    "\n",
    "기본 튜토리얼 [URL](https://github.com/tensorflow/docs/blob/master/site/en/guide/eager.ipynb)\n",
    "\n",
    "* tf.eager\n",
    "* tf.keras\n",
    "* tf.GradientTape()\n",
    "* Variables and optimizers\n",
    "* Use objects for state during eager execution\n",
    "* Custom gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU found\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LeakyReLU\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "if tf.test.gpu_device_name():\n",
    "    print('GPU found')\n",
    "else:\n",
    "    print(\"No GPU found\")\n",
    "\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello, [[4.]]\n"
     ]
    }
   ],
   "source": [
    "x = [[2.]]\n",
    "m = tf.matmul(x, x)\n",
    "print(\"hello, {}\".format(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1 2]\n",
      " [3 4]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([[1,2],[3,4]])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[2 3]\n",
      " [4 5]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Broadcasting support\n",
    "b = tf.add(a, 1)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 2  6]\n",
      " [12 20]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Operator overloading is supported\n",
    "print(a * b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Obtain numpy value from a tensor:\n",
    "print(a.numpy())\n",
    "# => [[1 2]\n",
    "#     [3 4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfe = tf.contrib.eager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fizzbuzz(max_num):\n",
    "    counter = tf.constant(0)\n",
    "    max_num = tf.convert_to_tensor(max_num)\n",
    "    for num in range(1, max_num.numpy()+1):\n",
    "        num = tf.constant(num)\n",
    "        if int(num % 3) == 0 and int(num % 5) == 0:\n",
    "            print('FizzBuzz')\n",
    "        elif int(num % 3) == 0:\n",
    "            print('Fizz')\n",
    "        elif int(num % 5) == 0:\n",
    "            print('Buzz')\n",
    "        else:\n",
    "            print(num.numpy())\n",
    "            print(num)\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "2\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "Fizz\n",
      "4\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "Buzz\n",
      "Fizz\n",
      "7\n",
      "tf.Tensor(7, shape=(), dtype=int32)\n",
      "8\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "Fizz\n",
      "Buzz\n",
      "11\n",
      "tf.Tensor(11, shape=(), dtype=int32)\n",
      "Fizz\n",
      "13\n",
      "tf.Tensor(13, shape=(), dtype=int32)\n",
      "14\n",
      "tf.Tensor(14, shape=(), dtype=int32)\n",
      "FizzBuzz\n"
     ]
    }
   ],
   "source": [
    "fizzbuzz(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build A Model\n",
    "\n",
    "* tf.keras.layers.Layer 를 활용하면 편하게 사용 할 수 있다고 한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySimpleLayer(tf.keras.layers.Layer) :\n",
    "    def __init__(self, output_units) :\n",
    "        super(MySimpleLayer , self).__init__()\n",
    "        self.output_units = output_units\n",
    "        \n",
    "    def build(self, input_shape) :\n",
    "        self.kernel = self.add_variable(\"kernel\" , [input_shape[-1] , self.output_units])\n",
    "    \n",
    "    def call(self, input) :\n",
    "        return tf.matmul(input , self.kernel )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `tf.keras.layers.Dense layer` instead of `MySimpleLayer` above as it has a superset of its functionality (it can also add a bias).\n",
    "\n",
    "When composing layers into models you can use tf.keras.Sequential to represent models which are a linear stack of layers. It is easy to use for basic models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x7f6e02048860>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10 , input_shape =(784,)),\n",
    "    tf.keras.layers.Dense(10) ,\n",
    "    tf.keras.layers.Dense(5),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 10)                7850      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 8,021\n",
      "Trainable params: 8,021\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf,keras.Model 로 부터 상속되서 모델을 만들 수 있다고 한다.\n",
    "* 음 잘 모르겠다 긁적"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTModel(tf.keras.Model) :\n",
    "    def __init__(self) :\n",
    "        super(MNISTModel, self).__init__()\n",
    "        self.dense1 = tf.keras.layers.Dense(units = 19)\n",
    "        self.dense2 = tf.keras.layers.Dense(units = 10)\n",
    "        \n",
    "    def call(self, input) :\n",
    "        result = self.dense1(input)\n",
    "        result = self.dense2(result)\n",
    "        result = self.dense2(result)\n",
    "        return result\n",
    "\n",
    "model = MNISTModel()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eager Training\n",
    "\n",
    "## Computing gradients\n",
    "\n",
    "*  `자동 미분`은 백프로퍼게이션을 할 때 유용하다. `eager`를 사용할 때는 `tf.GradientTape` 를 사용해 후에 Gradient를 계산할 때 `Trace` 할 수 있다고 한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[50.]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "w = tf.Variable([[5.0]])\n",
    "with tf.GradientTape() as tape :\n",
    "    loss = 5*w*w\n",
    "\n",
    "grad = tape.gradient(loss, w)\n",
    "print(grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델을 훈련시키기\n",
    "\n",
    "* MNIST 로 해보자\n",
    "* `tf.data`를 사용하면서 더 큰 모델에 잘 하는 것도 익혀두자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fetch and format the mnist data\n",
    "(mnist_images, mnist_labels), _ = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(\n",
    "  (tf.cast(mnist_images[...,tf.newaxis]/255, tf.float32),\n",
    "   tf.cast(mnist_labels,tf.int64)))\n",
    "\n",
    "dataset = dataset.shuffle(1000).batch(32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(16,[3,3],kernel_initializer='he_normal'),\n",
    "    tf.keras.layers.Activation(LeakyReLU()) ,\n",
    "    tf.keras.layers.Conv2D(16,[3,3], activation=\"relu\"),\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits:  [[-0.3427664   0.15773454 -0.26301625  0.42443573 -0.2069581  -0.12852414\n",
      "   0.20416534  0.3360661  -0.19809619 -0.01428229]]\n"
     ]
    }
   ],
   "source": [
    "for images,labels in dataset.take(1):\n",
    "    print(\"Logits: \", mnist_model(images[0:1]).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer()\n",
    "\n",
    "loss_history = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........................................"
     ]
    }
   ],
   "source": [
    "\n",
    "for (batch, (images, labels)) in enumerate(dataset.take(400)):\n",
    "    if batch % 10 == 0:\n",
    "        print('.', end='')\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = mnist_model(images, training=True)\n",
    "        loss_value = tf.losses.sparse_softmax_cross_entropy(labels, logits)\n",
    "\n",
    "    loss_history.append(loss_value.numpy())\n",
    "    grads = tape.gradient(loss_value, mnist_model.trainable_variables)\n",
    "    optimizer.apply_gradients( zip(grads, mnist_model.trainable_variables),\n",
    "                               global_step=tf.train.get_or_create_global_step() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(loss_history)\n",
    "plt.xlabel('Batch #')\n",
    "plt.ylabel('Loss [entropy]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables and optimizers\n",
    "* `tf.Variable objects` store `mutable tf.Tensor` values accessed during training to make `automatic differentiation easier.`\n",
    "\n",
    "* Better encapsulate model parameters by using `tf.Variable with tf.GradientTape`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss: 13.692\n"
     ]
    }
   ],
   "source": [
    "class Model(tf.keras.Model) :\n",
    "    def __init__(self) :\n",
    "        super(Model , self).__init__()\n",
    "        self.W = tf.Variable(5. , name = \"weight\")\n",
    "        self.B = tf.Variable(5. , name = \"bias\")\n",
    "    \n",
    "    def call(self, inputs) :\n",
    "        return inputs* self.W + self.B\n",
    "\n",
    "NUM_EXAMPLES = 2000\n",
    "training_inputs = tf.random_normal([NUM_EXAMPLES])\n",
    "noise = tf.random_normal([NUM_EXAMPLES])\n",
    "training_outputs = training_inputs * 3 +2 + noise\n",
    "\n",
    "def loss(model , inputs , targets) :\n",
    "    \"\"\"MSE\"\"\"\n",
    "    error = model(inputs ) - targets \n",
    "    return tf.reduce_mean(tf.square(error))\n",
    "\n",
    "def grad( model , inputs , targets ) :\n",
    "    with tf.GradientTape() as tape :\n",
    "        loss_value = loss(model , inputs , targets)\n",
    "    return tape.gradient(loss_value ,[model.W , model.B])\n",
    "\n",
    "model = Model()\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "\n",
    "print(\"Initial loss: {:.3f}\".format(loss(model, training_inputs, training_outputs)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 000: 9.130\n",
      "Loss at step 020: 0.997\n",
      "Loss at step 040: 0.996\n",
      "Loss at step 060: 0.996\n",
      "Loss at step 080: 0.996\n",
      "Loss at step 100: 0.996\n",
      "Loss at step 120: 0.996\n",
      "Loss at step 140: 0.996\n",
      "Loss at step 160: 0.996\n",
      "Loss at step 180: 0.996\n",
      "Loss at step 200: 0.996\n",
      "Loss at step 220: 0.996\n",
      "Loss at step 240: 0.996\n",
      "Loss at step 260: 0.996\n",
      "Loss at step 280: 0.996\n",
      "Final loss: 0.996\n",
      "W = 3.0158870220184326, B = 2.0361011028289795\n"
     ]
    }
   ],
   "source": [
    "for i in range(300) :\n",
    "    grads = grad(model , training_inputs , training_outputs)\n",
    "    optimizer.apply_gradients(zip(grads , [model.W , model.B]) ,\n",
    "                             global_step = tf.train.get_or_create_global_step())\n",
    "    \n",
    "    if i%20 ==0 :\n",
    "        print(\"Loss at step {:03d}: {:.3f}\".format(i, loss(model, training_inputs, training_outputs)))\n",
    "\n",
    "print(\"Final loss: {:.3f}\".format(loss(model, training_inputs, training_outputs)))\n",
    "print(\"W = {}, B = {}\".format(model.W.numpy(), model.B.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use objects for state during eager execution\n",
    "\n",
    "* With graph execution, program state (such as the variables) is stored in global collections and their lifetime is managed by the `tf.Session` object. \n",
    "* In contrast, `during eager execution` the lifetime of state objects is determined by the lifetime of their corresponding Python object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables are objects\n",
    "* During eager execution, variables persist until the last reference to the object is removed, and is then deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tf.test.is_gpu_available():\n",
    "    with tf.device(\"gpu:0\"):\n",
    "        v = tf.Variable(tf.random_normal([1000, 1000]))\n",
    "        v = None  # v no longer takes up GPU memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object-based saving\n",
    "* `tf.train.Checkpoint` can `save` and `restore` `tf.Variables` to and from checkpoints:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable(10.)\n",
    "checkpoint = tf.train.Checkpoint(x=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./ckpt/-1'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.assign(2.)   # Assign a new value to the variables and save.\n",
    "checkpoint_path = './ckpt/'\n",
    "checkpoint.save('./ckpt/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=() dtype=float32, numpy=11.0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the variable after saving.\n",
    "x.assign(11.)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* checkpint를 활용하여 `save` 한다음에 다시 `restore` 하니깐, 이전에 할당한 `x`는 사라지고 저장된 것이 불러와진다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n"
     ]
    }
   ],
   "source": [
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_path))\n",
    "\n",
    "print(x.numpy())  # => 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `To save and load models,` tf.train.Checkpoint stores the internal state of objects, without requiring hidden variables.\n",
    "* To record the state of a model, an optimizer, and a global step, pass them to a tf.train.Checkpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Conv2D(16,[3,3], activation='relu'),\n",
    "  tf.keras.layers.GlobalAveragePooling2D(),\n",
    "  tf.keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "checkpoint_dir = tempfile.mkdtemp()\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tmp/tmp5jj0dto2/ckpt'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                           model=model,\n",
    "                           optimizer_step=tf.train.get_or_create_global_step())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.checkpointable.util.CheckpointLoadStatus at 0x7f6d62a04240>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root.save(checkpoint_prefix)\n",
    "root.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object-oriented metrics\n",
    "\n",
    "* `tfe.metrics` are `stored as objects.` \n",
    "* Update a metric by passing the new data to the callable, and retrieve the result using the tfe.metrics.result method, \n",
    "\n",
    "> for example :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.5"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "m = tfe.metrics.Mean(\"loss\")\n",
    "m(0)\n",
    "m(5)\n",
    "m.result()  # => 2.5\n",
    "m([8, 9])\n",
    "m.result()  # => 5.5\n",
    "m.result().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summaries and TensorBoard\n",
    "\n",
    "`TensorBoard` is a visualization tool for understanding, debugging and optimizing the model training process. \n",
    "* It uses summary events that are written while executing the program.\n",
    "\n",
    "`tf.contrib.summary` is compatible with both eager and graph execution environments. \n",
    "Summary operations, such as `tf.contrib.summary.scalar`, are inserted during model construction. \n",
    "\n",
    "For example, to record summaries once every 100 global steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step = tf.train.get_or_create_global_step()\n",
    "logdir = \"./tb/\"\n",
    "writer = tf.contrib.summary.create_file_writer(logdir)\n",
    "writer.set_as_default()\n",
    "\n",
    "for _ in range(10):\n",
    "    global_step.assign_add(1)\n",
    "  # Must include a record_summaries method\n",
    "    with tf.contrib.summary.record_summaries_every_n_global_steps(100):\n",
    "        # your model code goes here\n",
    "        tf.contrib.summary.scalar('global_step', global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "events.out.tfevents.1549792897.esc8000g42.v2\r\n"
     ]
    }
   ],
   "source": [
    "!ls tb/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced automatic differentiation topics\n",
    "\n",
    "* Dynamic models\n",
    "\n",
    "* `tf.GradientTape` can also be used in dynamic models. \n",
    "\n",
    "* This example for a backtracking `line search algorithm` looks like normal NumPy code, except there are gradients and is differentiable, despite the complex control flow:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_search_step(fn, init_x, rate=1.0):\n",
    "    with tf.GradientTape() as tape:\n",
    "    # Variables are automatically recorded, but manually watch a tensor\n",
    "        tape.watch(init_x)\n",
    "        value = fn(init_x)\n",
    "    grad = tape.gradient(value, init_x)\n",
    "    grad_norm = tf.reduce_sum(grad * grad)\n",
    "    init_value = value\n",
    "    while value > init_value - rate * grad_norm:\n",
    "        x = init_x - rate * grad\n",
    "        value = fn(x)\n",
    "        rate /= 2.0\n",
    "    return x, value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional functions to compute gradients\n",
    "\n",
    "* `tf.GradientTape` is a powerful interface for computing gradients, `but` there is another Autograd-style API available for automatic differentiation. \n",
    "* These functions are useful if writing math code with only tensors and gradient functions, and `without tf.variables`:\n",
    "    * `tfe.gradients_function` —Returns a function that computes the derivatives of its input function parameter with respect to its arguments. \n",
    "    The input function parameter must return a scalar value. \n",
    "    \n",
    "    When the returned function is invoked, it returns a list of tf.Tensor objects: one element for each argument of the input function. \n",
    "    \n",
    "    Since anything of interest must be passed as a function parameter, this becomes unwieldy if there's a dependency on many trainable parameters.\n",
    "    \n",
    "    * `tfe.value_and_gradients_function` —Similar to tfe.gradients_function, but when the returned function is invoked, it returns the value from the input function in addition to the list of derivatives of the input function with respect to its arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square(x):\n",
    "    return tf.multiply(tf.square(x), x)\n",
    "\n",
    "grad = tfe.gradients_function(square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.0"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "square(3.).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad(3.)[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "The second-order derivative of square:\n",
    "\"\"\"\n",
    "\n",
    "gradgrad = tfe.gradients_function(lambda x: grad(x)[0])\n",
    "gradgrad(3.)[0].numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "The third-order derivative is None:\n",
    "\"\"\"\n",
    "\n",
    "gradgradgrad = tfe.gradients_function(lambda x: gradgrad(x)[0])\n",
    "gradgradgrad(3.)[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abs(x):\n",
    "    return x if x > 0. else -x\n",
    "\n",
    "grad = tfe.gradients_function(abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad(3.)[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad(-3.)[0].numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Gradients\n",
    "\n",
    "* `Custom gradients` are an easy way to override gradients in eager and graph execution. \n",
    "* Within the forward function, define the gradient with respect to the inputs, outputs, or intermediate results. \n",
    "\n",
    "> For example, here's an easy way to clip the norm of the gradients in the backward pass:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.custom_gradient\n",
    "def clip_gradient_by_norm(x, norm):\n",
    "    y = tf.identity(x)\n",
    "    def grad_fn(dresult):\n",
    "        return [tf.clip_by_norm(dresult, norm), None]\n",
    "    return y, grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log1pexp(x):\n",
    "    return tf.log(1 + tf.exp(x))\n",
    "grad_log1pexp = tfe.gradients_function(log1pexp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9933072"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The gradient computation works fine at x = 0.\n",
    "grad_log1pexp(5.)[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "However, x = 100 fails because of numerical instability.\n",
    "\"\"\"\n",
    "\n",
    "grad_log1pexp(100.)[0].numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* the `log1pexp` function can be analytically simplified with `a custom gradient.` \n",
    "\n",
    "* The implementation below `reuses the value for tf.exp(x)` that is computed during the forward pass—making it more efficient by eliminating redundant calculations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@tf.custom_gradient\n",
    "def log1pexp(x):\n",
    "    e = tf.exp(x)\n",
    "    def grad(dy):\n",
    "        return dy * (1 - 1 / (1 + e))\n",
    "    return tf.log(1 + e), grad\n",
    "\n",
    "grad_log1pexp = tfe.gradients_function(log1pexp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As before, the gradient computation works fine at x = 0.\n",
    "grad_log1pexp(0.)[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "And the gradient computation also works at x = 100.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "grad_log1pexp(100.)[0].numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance\n",
    "\n",
    "\n",
    "Computation is automatically offloaded to GPUs during eager execution. If you want control over where a computation runs you can enclose it in a tf.device('/gpu:0') block (or the CPU equivalent):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to multiply a (1000, 1000) matrix by itself 200 times:\n",
      "CPU: 0.9748802185058594 secs\n",
      "GPU: not found\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def measure(x, steps):\n",
    "    # TensorFlow initializes a GPU the first time it's used, exclude from timing.\n",
    "    tf.matmul(x, x)\n",
    "    start = time.time()\n",
    "    for i in range(steps):\n",
    "        x = tf.matmul(x, x)\n",
    "  # tf.matmul can return before completing the matrix multiplication\n",
    "  # (e.g., can return after enqueing the operation on a CUDA stream).\n",
    "  # The x.numpy() call below will ensure that all enqueued operations\n",
    "  # have completed (and will also copy the result to host memory,\n",
    "  # so we're including a little more than just the matmul operation\n",
    "  # time).\n",
    "    _ = x.numpy()\n",
    "    end = time.time()\n",
    "    return end - start\n",
    "\n",
    "shape = (1000, 1000)\n",
    "steps = 200\n",
    "print(\"Time to multiply a {} matrix by itself {} times:\".format(shape, steps))\n",
    "\n",
    "# Run on CPU:\n",
    "with tf.device(\"/cpu:0\"):\n",
    "    print(\"CPU: {} secs\".format(measure(tf.random_normal(shape), steps)))\n",
    "\n",
    "# Run on GPU, if available:\n",
    "if tfe.num_gpus() > 0:\n",
    "    with tf.device(\"/gpu:0\"):\n",
    "        print(\"GPU: {} secs\".format(measure(tf.random_normal(shape), steps)))\n",
    "else:\n",
    "    print(\"GPU: not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tf.test.is_gpu_available():\n",
    "    x = tf.random_normal([10, 10])\n",
    "\n",
    "    x_gpu0 = x.gpu()\n",
    "    x_cpu = x.cpu()\n",
    "\n",
    "    _ = tf.matmul(x_cpu, x_cpu)    # Runs on CPU\n",
    "    _ = tf.matmul(x_gpu0, x_gpu0)  # Runs on GPU:0\n",
    "\n",
    "    if tfe.num_gpus() > 1:\n",
    "        x_gpu1 = x.gpu(1)\n",
    "        _ = tf.matmul(x_gpu1, x_gpu1)  # Runs on GPU:1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work with graphs\n",
    "\n",
    "* While eager execution makes development and debugging more interactive, tensorFlow graph execution has advantages for distributed training, performance optimizations, and production deployment.\n",
    "\n",
    "* `However`, `writing graph code` can feel different than writing regular Python code and more `difficult to debug`.\n",
    "\n",
    "For building and training graph-constructed models, the Python program first builds a graph representing the computation, then invokes Session.run to send the graph for execution on the C++-based runtime. This provides:\n",
    "\n",
    "* Automatic differentiation using static autodiff.\n",
    "* Simple deployment to a platform independent server.\n",
    "* Graph-based optimizations (common subexpression elimination, constant-folding, etc.).\n",
    "* Compilation and kernel fusion.\n",
    "* Automatic distribution and replication (placing nodes on the distributed system).\n",
    "\n",
    "\n",
    "`Deploying code written for eager execution is more difficult` \n",
    "* either generate a graph from the model, or run the Python runtime and code directly on the server.\n",
    "\n",
    "## Write compatible code\n",
    "\n",
    "`The same code written for eager execution` will also build a graph during graph execution. \n",
    "* Do this by simply running the same code in a new Python session where eager execution is not enabled.\n",
    "\n",
    "Most TensorFlow operations work during eager execution, but there are some things to `keep in mind`:\n",
    "\n",
    "* `Use tf.data for input processing instead of queues`. **It's faster and easier.**\n",
    "* `Use object-oriented layer APIs—like tf.keras.layers and tf.keras.Model` **since they have explicit storage for variables.**\n",
    "* Most model code works **the same** `during eager and graph execution`, but there are exceptions. (For example, dynamic models using Python control flow to change the computation based on inputs.)\n",
    "* `Once eager execution` is enabled with tf.enable_eager_execution, it `cannot be turned off`. `Start a new Python session to return to graph execution.`\n",
    "\n",
    "## [example](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/eager/python/examples)\n",
    "### 다음에는 위에 있는 example을 보면서 연습을 해봐야겠다.\n",
    "\n",
    "## Use eager execution in a graph environment\n",
    "\n",
    "* `Selectively` `enable` **eager execution in a TensorFlow graph** environment using `tfe.py_func.` * This is used when tf.enable_eager_execution() has not been called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[4.]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def my_py_func(x):\n",
    "    x = tf.matmul(x, x)  # You can use tf ops\n",
    "    print(x)  # but it's eager!\n",
    "    return x\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    x = tf.placeholder(dtype=tf.float32)\n",
    "  # Call eager function in graph!\n",
    "    pf = tfe.py_func(my_py_func, [x], tf.float32)\n",
    "  \n",
    "    sess.run(pf, feed_dict={x: [[2.0]]})  # [[4.0]]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 공부할 것은 많구만................."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
