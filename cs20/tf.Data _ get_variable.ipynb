{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"tf.Data / get_variable.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"OJlzF3zfCT74","colab_type":"text"},"cell_type":"markdown","source":["## https://docs.google.com/document/d/1kMGs68rIHWHifBiqlU3j_2ZkrNj9RquGTe8tJ7eR1sE/edit"]},{"metadata":{"id":"1K4JkP2z_FuZ","colab_type":"text"},"cell_type":"markdown","source":["# Placeholder\n","\n","Pro: put the data processing outside TensorFlow, making it easy to do in Python\n","\n","Cons: users often end up processing their data in a single thread and creating data bottleneck that slows execution down.\n","\n","\n","\n","```\n","data, n_samples = utils.read_birth_life_data(DATA_FILE)\n","X = tf.placeholder(tf.float32, name='X')\n","Y = tf.placeholder(tf.float32, name='Y')\n","…\n","with tf.Session() as sess:\n","       …\n","\t# Step 8: train the model\n","\tfor i in range(100): # run 100 epochs\n","\t\tfor x, y in data:\n","\t\t\t# Session runs train_op to minimize loss\n","\t\t\tsess.run(optimizer, feed_dict={X: x, Y:y})\n","```\n","\n"]},{"metadata":{"id":"ndE3w19c_TEF","colab_type":"text"},"cell_type":"markdown","source":["# tf.data\n","\n","Instead of doing inference with **placeholders** and feeding in data later, do inference directly with data\n","\n","tf.data.Dataset\n","\n","tf.data.Iterator\n","\n","## Store data in tf.data.Dataset\n","\n","```\n","tf.data.Dataset.from_tensor_slices((features, labels))\n","tf.data.Dataset.from_generator(gen, output_types, output_shapes)\n","\n","tf.data.Dataset.from_tensor_slices((features, labels))\n","dataset = tf.data.Dataset.from_tensor_slices((data[:,0], data[:,1]))\n","\n","tf.data.Dataset.from_tensor_slices((features, labels))\n","dataset = tf.data.Dataset.from_tensor_slices((data[:,0], data[:,1]))\n","print(dataset.output_types)\t\t# >> (tf.float32, tf.float32)\n","print(dataset.output_shapes)\t\t# >> (TensorShape([]), TensorShape([]))\n","\n","```\n","## Can also create Dataset from files\n","\n","\n","\n","```\n","tf.data.TextLineDataset(filenames)\n","tf.data.FixedLengthRecordDataset(filenames)\n","tf.data.TFRecordDataset(filenames)\n","\n","```\n","## tf.data.Iterator\n","\n","```\n","Create an iterator to iterate through samples in Dataset\n","\n","iterator = dataset.make_one_shot_iterator()\n","iterator = dataset.make_initializable_iterator()\n","\n","iterator = dataset.make_one_shot_iterator()\n","# Iterates through the dataset exactly once. No need to initialization.\n","\n","iterator = dataset.make_initializable_iterator()\n","# Iterates through the dataset as many times as we want. Need to initialize with each epoch.\n","\n","terator = dataset.make_one_shot_iterator()\n","X, Y = iterator.get_next()         # X is the birth rate, Y is the life expectancy\n","with tf.Session() as sess:\n","\tprint(sess.run([X, Y]))\t\t# >> [1.822, 74.82825]\n","\tprint(sess.run([X, Y]))\t\t# >> [3.869, 70.81949]\n","\tprint(sess.run([X, Y]))\t\t# >> [3.911, 72.15066]\n","  \n"," \n","terator = dataset.make_initializable_iterator()\n","..................................................\n","for i in range(100): \n","        sess.run(iterator.initializer) \n","        total_loss = 0\n","        try:\n","            while True:\n","                sess.run([optimizer]) \n","        except tf.errors.OutOfRangeError:\n","            pass\n","\n","```\n","\n","\n","\n"]},{"metadata":{"id":"una-LM6CAHTt","colab_type":"text"},"cell_type":"markdown","source":["##  Handling data in TensorFlow\n","\n","```\n","dataset = dataset.shuffle(1000)\n","dataset = dataset.repeat(100)\n","dataset = dataset.batch(128)\n","dataset = dataset.map(lambda x: tf.one_hot(x, 10)) \n","# convert each elem of dataset to one_hot vector\n","```\n","# Does tf.data really perform better?\n","\n","With placeholder: **9.05271519** seconds\n","\n","With **tf.data**: **6.12285947** seconds\n","\n","## Should we always use tf.data?\n","\n","For prototyping, feed dict can be faster and easier to write (pythonic)\n","\n","tf.data is tricky to use when you have complicated preprocessing or multiple data sources\n","\n","NLP data is normally just a sequence of integers. In this case, transferring the data over to GPU is pretty quick, \n","\n","so the speedup of tf.data isn't that large\n"]},{"metadata":{"id":"BN1IYIkIAkAd","colab_type":"text"},"cell_type":"markdown","source":["# Optimizer\n","\n","```\n","optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(loss)\n","\n","_, l = sess.run([optimizer, loss], feed_dict={X: x, Y:y})\n","\n","```\n","Session looks at all trainable variables that loss depends on and update them\n","\n","## Trainable variables\n","\n","Specify if a variable should be trained or not\n","\n","By default, all variables are trainable\n","\n","```\n","\n","tf.Variable(initial_value=None, trainable=True,...)\n","```\n","For example, global_steps shouldn’t be trainable\n","\n","Or in double q-learning, you want to alternate which q-value functions to update\n","\n","\n","\n"]},{"metadata":{"id":"LhFwHdMlBP9S","colab_type":"text"},"cell_type":"markdown","source":["\n","## good code\n","```\n","mnist_folder = 'data/mnist'\n","utils.download_mnist(mnist_folder)\n","train, val, test = utils.read_mnist(mnist_folder, flatten=True)\n","\n","train_data = tf.data.Dataset.from_tensor_slices(train)\n","train_data = train_data.shuffle(10000) # optional\n","test_data = tf.data.Dataset.from_tensor_slices(test)\n","### 이부분이 굳 잡 두번할꺼 한번으로 줄임 \n","iterator = tf.data.Iterator.from_structure(train_data.output_types, \n","                                           train_data.output_shapes)\n","img, label = iterator.get_next()\n","\n","train_init = iterator.make_initializer(train_data)\t# initializer for train_data\n","test_init = iterator.make_initializer(test_data)\t# initializer for train_data\n"," =-------==============================================================================\n","## Initialize iterator with the dataset you want \n","\n","\n","with tf.Session() as sess:\n","    ...\n","    for i in range(n_epochs):       \n","        sess.run(train_init)\t       \t# use train_init during training loop\n","        try:\n","            while True:\n","                _, l = sess.run([optimizer, loss])\n","        except tf.errors.OutOfRangeError:\n","            pass\n"," \n","    # test the model\n","    sess.run(test_init)\t\t\t\t# use test_init during testing\n","    try:\n","        while True:\n","            sess.run(accuracy)\n","    except tf.errors.OutOfRangeError:\n","        pass\n","\n","```\n","\n"]},{"metadata":{"id":"NJ7VECbMBh3I","colab_type":"text"},"cell_type":"markdown","source":["# tf.get_varialbe()\n","\n","With tf.get_variable, we can provide variable’s internal name, shape, type, and initializer to give the variable its initial value. Note that when we use tf.constant as an initializer, we don’t need to provide shape.\n","\n","```\n","tf.get_variable(\n","    name,\n","    shape=None,\n","    dtype=None,\n","    initializer=None,\n","    regularizer=None,\n","    trainable=True,\n","    collections=None,\n","    caching_device=None,\n","    partitioner=None,\n","    validate_shape=True,\n","    use_resource=None,\n","    custom_getter=None,\n","    constraint=None\n",")\n","\n","s = tf.get_variable(\"scalar\", initializer=tf.constant(2)) \n","m = tf.get_variable(\"matrix\", initializer=tf.constant([[0, 1], [2, 3]]))\n","W = tf.get_variable(\"big_matrix\", shape=(784, 10), initializer=tf.zeros_initializer())\n","\n","```\n","You have to initialize a variable before using it. If you try to evaluate the variables before initializing them you'll run into FailedPreconditionError: Attempting to use uninitialized value. To get a list of uninitialized variables, you can just print them out:\n","\n","```\n","print(session.run(tf.report_uninitialized_variables()))\n","```\n","\n","\n"]},{"metadata":{"id":"pMEm7uQ7-_3P","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}